{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjiczGY_ZgDI",
        "outputId": "69780c52-ddc6-4d56-b69e-d58b5304526c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.0.1+cu118)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.1->torchvision) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.1->torchvision) (16.0.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.1->torchvision) (1.3.0)\n",
            "Collecting deeplake\n",
            "  Downloading deeplake-3.7.0.tar.gz (554 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m554.4/554.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.23.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from deeplake) (9.4.0)\n",
            "Collecting boto3 (from deeplake)\n",
            "  Downloading boto3-1.28.53-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeplake) (8.1.7)\n",
            "Collecting pathos (from deeplake)\n",
            "  Downloading pathos-0.3.1-py3-none-any.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humbug>=0.3.1 (from deeplake)\n",
            "  Downloading humbug-0.3.2-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from deeplake) (4.66.1)\n",
            "Collecting numcodecs (from deeplake)\n",
            "  Downloading numcodecs-0.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from deeplake) (2.3.0)\n",
            "Collecting aioboto3>=10.4.0 (from deeplake)\n",
            "  Downloading aioboto3-11.3.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.5.7)\n",
            "Collecting aiobotocore[boto3]==2.6.0 (from aioboto3>=10.4.0->deeplake)\n",
            "  Downloading aiobotocore-2.6.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting botocore<1.31.18,>=1.31.17 (from aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake)\n",
            "  Downloading botocore-1.31.17-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.7.4.post0 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake) (3.8.5)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake) (1.15.0)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake)\n",
            "  Downloading aioitertools-0.11.0-py3-none-any.whl (23 kB)\n",
            "Collecting boto3 (from deeplake)\n",
            "  Downloading boto3-1.28.17-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->deeplake)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->deeplake)\n",
            "  Downloading s3transfer-0.6.2-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from humbug>=0.3.1->deeplake) (2.31.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from numcodecs->deeplake) (0.4)\n",
            "Collecting ppft>=1.7.6.7 (from pathos->deeplake)\n",
            "  Downloading ppft-1.7.6.7-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill>=0.3.7 (from pathos->deeplake)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pox>=0.3.3 (from pathos->deeplake)\n",
            "  Downloading pox-0.3.3-py3-none-any.whl (29 kB)\n",
            "Collecting multiprocess>=0.70.15 (from pathos->deeplake)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.31.18,>=1.31.17->aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4 (from botocore<1.31.18,>=1.31.17->aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->humbug>=0.3.1->deeplake) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->humbug>=0.3.1->deeplake) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->humbug>=0.3.1->deeplake) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.7.4.post0->aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.31.18,>=1.31.17->aiobotocore[boto3]==2.6.0->aioboto3>=10.4.0->deeplake) (1.16.0)\n",
            "Building wheels for collected packages: deeplake\n",
            "  Building wheel for deeplake (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deeplake: filename=deeplake-3.7.0-py3-none-any.whl size=668719 sha256=c197041757db661983c4ef8b5b9fa97ea5d9a47dbd1db7cdaadd0a4add07414f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/22/e7/6bc495c1d61555636ce18d689077030ee1222573bb4412e67f\n",
            "Successfully built deeplake\n",
            "Installing collected packages: urllib3, ppft, pox, numcodecs, jmespath, dill, aioitertools, multiprocess, botocore, s3transfer, pathos, humbug, aiobotocore, boto3, aioboto3, deeplake\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "Successfully installed aioboto3-11.3.0 aiobotocore-2.6.0 aioitertools-0.11.0 boto3-1.28.17 botocore-1.31.17 deeplake-3.7.0 dill-0.3.7 humbug-0.3.2 jmespath-1.0.1 multiprocess-0.70.15 numcodecs-0.11.0 pathos-0.3.1 pox-0.3.3 ppft-1.7.6.7 s3transfer-0.6.2 urllib3-1.26.16\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (1.26.16)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-2.0.5-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.26.16\n",
            "    Uninstalling urllib3-1.26.16:\n",
            "      Successfully uninstalled urllib3-1.26.16\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "botocore 1.31.17 requires urllib3<1.27,>=1.25.4, but you have urllib3 2.0.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed urllib3-2.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install deeplake\n",
        "!pip install --upgrade urllib3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vBijcDw-7hHu"
      },
      "outputs": [],
      "source": [
        "import torch as torch\n",
        "import torch.nn as nn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import zipfile\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import Dataset, DataLoader,Subset\n",
        "import deeplake\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXh-Ydvh0YaR"
      },
      "source": [
        "## Model Training and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class LeafDataset(Dataset):\n",
        "  def __init__(self):#, file_path):\n",
        "    super().__init__()\n",
        "    self.ds = deeplake.load('hub://activeloop/plantvillage-with-augmentation')\n",
        "    self.transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((350,350)),\n",
        "        transforms.Normalize(0.5,0.5)\n",
        "\n",
        "    ])\n",
        "    total_data = 58775\n",
        "    split_size = int(0.8*total_data)\n",
        "    self.batch_size = 500 \n",
        "    train_dataset = self.ds[:split_size]\n",
        "    test_dataset = self.ds[split_size: total_data]\n",
        "    self.train_data = test_dataset.pytorch(num_workers = 0, shuffle = True, transform = {'images': self.transform, 'labels': None}, batch_size = self.batch_size, decode_method = {'images': 'pil'})\n",
        "    self.test_data = test_dataset.pytorch(num_workers = 0, shuffle = True, transform = {'images': self.transform, 'labels': None}, batch_size = self.batch_size, decode_method = {'images': 'pil'})\n",
        "   \n",
        "  def __len__(self):\n",
        "    return len(self.ds)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    return self.ds[index]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TRAIN MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoClyILQLQ-b",
        "outputId": "b34d6389-3a49-4dfe-8a3e-be51426080af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\\"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Opening dataset in read-only mode as you don't have write permissions.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This dataset can be visualized in Jupyter Notebook by ds.visualize() or at https://app.activeloop.ai/activeloop/plantvillage-with-augmentation\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hub://activeloop/plantvillage-with-augmentation loaded successfully.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\r \r\r\r/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class LeafModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LeafModel,self).__init__()\n",
        "    # Define the layers\n",
        "    self.conv1 = nn.Conv2d(3,10,kernel_size = 7)\n",
        "    self.conv2 = nn.Conv2d(10,24,kernel_size = 7)\n",
        "    self.conv3 = nn.Conv2d(24,64,kernel_size = 6)\n",
        "    #self.conv4 = nn.Conv2D(40,64,kernel_size = 6)\n",
        "    self.conv4 = nn.Conv2d(64,180,kernel_size = 6)\n",
        "    self.fc1    = nn.Linear(35280,100)\n",
        "    self.fc2    = nn.Linear(100,64)\n",
        "    self.fc3    = nn.Linear(64,39)\n",
        "    # Classes = 39\n",
        "\n",
        "  def forward(self,x):\n",
        "    # print(x)\n",
        "    # print(x.shape)\n",
        "    x = F.relu(self.conv1(x))\n",
        "    x = F.max_pool2d(x, kernel_size = 5, stride = 2)\n",
        "    x = F.relu(self.conv2(x))\n",
        "    x = F.avg_pool2d(x, kernel_size = 5, stride = 2)\n",
        "    x = F.relu(self.conv3(x))\n",
        "    x = F.avg_pool2d(x, kernel_size = 5, stride = 2)\n",
        "    x = F.relu(self.conv4(x))\n",
        "    x = F.avg_pool2d(x, kernel_size = 5, stride = 2)\n",
        "    # print(x.shape)\n",
        "    x = x.view(x.size(0), -1)\n",
        "    # print(x.shape)\n",
        "    x = F.tanh(self.fc1(x))\n",
        "    # print(x.shape)\n",
        "    x = F.tanh(self.fc2(x))\n",
        "    # print(x.shape)\n",
        "    x = F.softmax(self.fc3(x, ),dim = -1)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "# MAIN PROGRAM\n",
        "\n",
        "dataset = LeafDataset()\n",
        "model = LeafModel()\n",
        "\n",
        "# criterion = nn.MSELoss()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "#     TRAINING\n",
        "#------------------------------------------------------------------------------\n",
        "batch_size = dataset.batch_size\n",
        "num_epochs = 6\n",
        "total_train = int(58775*0.8)   # Total data points in the training dataset\n",
        "all_losses = list()\n",
        "all_accuracies = list()\n",
        "\n",
        "\n",
        "# for images,labels in dataset.train_data:\n",
        "#   model.train()\n",
        "for epoch in range(num_epochs):\n",
        "  correct = 0\n",
        "  loss = 0.0\n",
        "  model.train()\n",
        "  for images,labels in dataset.train_data:\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(images)\n",
        "    \n",
        "    labels = torch.tensor([int(x[0]) for x in labels])#, dtype = torch.float32,requires_grad=True)\n",
        "    # print(labels)\n",
        "    \n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    loss += loss.item()\n",
        "    print(loss)\n",
        "\n",
        "    # torch.max() returns two outputs, the maximum values and the corresponding index\n",
        "    # We are intersted in the index, which is equivalent to the predicted digit\n",
        "    _ ,predictions =  torch.max(outputs.data,1)     # Get maximum values in the output tensor, along the second dimension\n",
        "\n",
        "    # Compare the predictions against labels, and count the correct ones\n",
        "    correct += sum([predictions[i] == labels[i] for i in range(0,images.shape[0])])\n",
        "    \n",
        "    # print(correct)\n",
        "\n",
        "  print('\\n Loss for epoch ',epoch,': ',loss.item()/batch_size)\n",
        "  print('\\n Accuracy for epoch ',epoch,': ',(correct/total_train).numpy())\n",
        "  all_losses.append(loss.item()/batch_size)\n",
        "  all_accuracies.append(correct/total_train)\n",
        "\n",
        "# PLOT THE LOSSES\n",
        "plt.plot(list(range(num_epochs)),all_losses)\n",
        "#for epoch,loss in zip(list(range(num_epochs)),all_losses):\n",
        "#    plt.text(epoch, loss+500, str(int(loss)))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Losses\")\n",
        "plt.title(\"Plot of training loss after each epoch\")\n",
        "plt.show()\n",
        "\n",
        "# PLOT THE ACCURACY\n",
        "plt.plot(list(range(num_epochs)),all_accuracies,color= \"orange\")\n",
        "#for epoch,accuracy in zip(list(range(num_epochs)),all_accuracies):\n",
        "#    plt.text(epoch, accuracy+500, str(int(accuracy)))\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"Plot of training accuracy after each epoch\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ilOjH9qcTDM"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pbou-p6tOJT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjYUKYgutOGH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2bUop4HlnwT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
